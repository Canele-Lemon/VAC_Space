# VACJacobianTrainer.py
import os, sys, joblib, json
import numpy as np
import pandas as pd
from dataclasses import dataclass
from typing import Tuple, Dict, List

from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# í”„ë¡œì íŠ¸ ê²½ë¡œ
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from scripts.VAC_dataset import VACDataset  # ì´ë¯¸ ì‚¬ìš© ì¤‘ì¸ Dataset

# ------------------------
# ì„¤ì •
# ------------------------
KNOTS = 33                     # High/Low ì»¨íŠ¸ë¡¤ í¬ì¸íŠ¸ ê°œìˆ˜(ê¶Œì¥: 9~33)
PATTERNS = ['W']   # Y0ì˜ íŒ¨í„´
COMPONENTS = ['Gamma','Cx','Cy']
RANDOM_STATE = 42

save_dir = os.path.dirname(__file__)
out_path = os.path.join(save_dir, "jacobian_Y0_high_K33.pkl")

# ------------------------
# ìœ í‹¸: knot & basis
# ------------------------
# jacobian_train_offline.py (í˜¹ì€ ë‹¹ì‹ ì˜ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨)
def build_pk_list_for_jacobian():
    blocks = [
        range(1411, 1934),   # 1411~1933
        range(1935, 2154),    # 1935~2153
        range(2155, 2455),     # 2155~2454
    ]
    pk_set = set()
    for b in blocks:
        pk_set.update(b)
    pk_list = sorted(pk_set)
    print(f"[Jacobian] using {len(pk_list)} PKs")
    return pk_list

def make_knot_positions(L=256, K=KNOTS) -> np.ndarray:
    # [0..255] êµ¬ê°„ì—ì„œ ë™ì¼ ê°„ê²© ë…¸ë“œ ì¸ë±ìŠ¤
    return np.round(np.linspace(0, L-1, K)).astype(int)

def linear_interp_weights(g: int, knots: np.ndarray) -> np.ndarray:
    """
    ê·¸ë ˆì´ g(0..255)ì— ëŒ€í•´, Kê°œ knotì— ëŒ€í•œ ì„ í˜•ë³´ê°„ 'ëª¨ì(hat)' ê°€ì¤‘ì¹˜ ë²¡í„° Ï†(g) ë°˜í™˜.
    - ì–‘ ëì€ 1ê°œ, ì¤‘ê°„ì€ 2ê°œ ë…¸ë“œë§Œ ë¹„ì˜(í¬ì†Œ)
    """
    K = len(knots)
    w = np.zeros(K, dtype=np.float32)
    # ì™¼ìª½/ì˜¤ë¥¸ìª½ ê²½ê³„
    if g <= knots[0]:
        w[0] = 1.0
        return w
    if g >= knots[-1]:
        w[-1] = 1.0
        return w
    # ë‚´ë¶€: ì¸ì ‘í•œ ë‘ knot ì‚¬ì´
    i = np.searchsorted(knots, g) - 1
    g0, g1 = knots[i], knots[i+1]
    t = (g - g0) / max(1, (g1 - g0))
    w[i]   = 1.0 - t
    w[i+1] = t
    return w

def stack_basis_all_grays(knots: np.ndarray, L=256) -> np.ndarray:
    """
    ëª¨ë“  ê·¸ë ˆì´(0..255)ì— ëŒ€í•œ Ï†(g) Kì°¨ì› ê°€ì¤‘ì¹˜ í–‰ë ¬ (L x K)
    """
    rows = [linear_interp_weights(g, knots) for g in range(L)]
    return np.vstack(rows).astype(np.float32)

# ------------------------
# í”¼ì²˜ êµ¬ì„±
# ------------------------
@dataclass
class FeatureSlices:
    high_R: slice
    high_G: slice
    high_B: slice
    low_R:  slice
    low_G:  slice
    low_B:  slice
    meta:   slice          # panel_onehot + frame_rate + model_year
    gray:   int            # meta slice ë‚´ë¶€ì—ì„œ gray_norm ìœ„ì¹˜ (í•„ìš”ì‹œ ì°¸ì¡°)
    pattern_oh: slice      # 4-dim

def build_feature_vector_for_gray(X_dict: dict, pattern: str, g: int,
                                  knots: np.ndarray, include_controls=True) -> Tuple[np.ndarray, FeatureSlices]:
    """
    ì…ë ¥:
      - X_dict: VACInputBuilder.prepare_X0() ê²°ê³¼
      - pattern: 'W','R','G','B' (íŒ¨í„´ ì›í•« í¬í•¨)
      - g: 0..255
      - knots: Kê°œ ë…¸ë“œ ì¸ë±ìŠ¤
    ì¶œë ¥:
      - feat: [High(R/G/B) knot-basis, (ì˜µì…˜) Low(R/G/B) knot-basis, meta, gray_norm, pattern_onehot(4)]
      - slices: ê° êµ¬ê°„ì˜ ìœ„ì¹˜ì •ë³´
    """
    lut = X_dict['lut']; meta = X_dict['meta']
    K = len(knots)

    # 1) High/Low knot ê°’ ì¶”ì¶œ (í˜„ì¬ ê³¡ì„ ì—ì„œ ë…¸ë“œ ìœ„ì¹˜ ìƒ˜í”Œ)
    #    - í•™ìŠµ ì‹œì—” 'í˜„ ìƒíƒœ ì ˆëŒ€ê°’'ì„ ì“°ì§€ë§Œ, ì„ í˜•ëª¨ë¸ì´ë¯€ë¡œ ê³„ìˆ˜ëŠ” 'ë³€í™”'ì— ì„ í˜•ì…ë‹ˆë‹¤.
    H_R = lut['R_High'][knots]; H_G = lut['G_High'][knots]; H_B = lut['B_High'][knots]
    L_R = lut['R_Low'][knots];  L_G = lut['G_Low'][knots];  L_B = lut['B_Low'][knots]

    # 2) gì—ì„œì˜ ë³´ê°„ ê°€ì¤‘ì¹˜ Ï†(g)
    phi = linear_interp_weights(g, knots)  # (K,)

    # 3) High/Low ê¸°ì €(íŠ¹ì§•): ì±„ë„ë³„ë¡œ Ï†(g) âŠ™ knot-value
    #    - ìì½”ë¹„ì•ˆ ê´€ì ì—ì„  'knot value' ìì²´ê°€ ë…ë¦½ë³€ìˆ˜ì´ë¯€ë¡œ, íŠ¹ì§•ìœ¼ë¡œ Ï†(g)ë§Œ ì¨ë„ ë¨.
    #      ì—¬ê¸°ì„œëŠ” "í˜„ì¬ knotê°’"ë„ í•¨ê»˜ ì“°ëŠ” ì ˆì¶©ì•ˆ(í˜„ì‹¤ ë°ì´í„° ì í•©ë ¥â†‘). 
    #    - ìˆœì „íˆ ìì½”ë¹„ì•ˆë§Œ ì›í•˜ë©´, ì•„ë˜ì—ì„œ H_R/G/B ëŒ€ì‹  'phi ìì²´'ë¥¼ ì“°ê³ 
    #      ë‚˜ì¤‘ì— ê³„ìˆ˜ í•´ì„ ì‹œ Î²ê°€ ìì½”ë¹„ì•ˆ ê·¸ ìì²´ê°€ ë©ë‹ˆë‹¤(ê¶Œì¥: 'phi-only' ëª¨ë“œ).
    # ---- [ê¶Œì¥] phi-only ëª¨ë“œ ----
    use_phi_only = True

    feats = []
    s = {}

    # High(R/G/B)
    idx0 = len(feats)
    if use_phi_only:
        feats.extend(phi); feats.extend(phi); feats.extend(phi)  # R,G,B
    else:
        feats.extend(phi * H_R); feats.extend(phi * H_G); feats.extend(phi * H_B)
    s_high_R = slice(idx0, idx0+K); idx0 += K
    s_high_G = slice(idx0, idx0+K); idx0 += K
    s_high_B = slice(idx0, idx0+K); idx0 += K

    # Low(R/G/B) - ì»¨íŠ¸ë¡¤ í”¼ì²˜
    if include_controls:
        if use_phi_only:
            feats.extend(phi); feats.extend(phi); feats.extend(phi)
        else:
            feats.extend(phi * L_R); feats.extend(phi * L_G); feats.extend(phi * L_B)
        s_low_R = slice(idx0, idx0+K); idx0 += K
        s_low_G = slice(idx0, idx0+K); idx0 += K
        s_low_B = slice(idx0, idx0+K); idx0 += K
    else:
        s_low_R = s_low_G = s_low_B = slice(idx0, idx0)

    # meta: panel_onehot + frame_rate + model_year
    panel = np.asarray(meta['panel_maker'], dtype=np.float32)
    feats.extend(panel.tolist())
    feats.append(float(meta['frame_rate']))
    feats.append(float(meta['model_year']))
    s_meta = slice(idx0, idx0 + len(panel) + 2); idx0 = s_meta.stop

    # gray_norm
    gray_norm = g/255.0
    feats.append(gray_norm)
    gray_pos = idx0; idx0 += 1

    # pattern one-hot (4)
    p_oh = np.zeros(4, np.float32)
    p_oh[['W','R','G','B'].index(pattern)] = 1.0
    feats.extend(p_oh.tolist())
    s_poh = slice(idx0, idx0+4); idx0 += 4

    feat = np.asarray(feats, dtype=np.float32)
    slices = FeatureSlices(
        high_R=s_high_R, high_G=s_high_G, high_B=s_high_B,
        low_R=s_low_R,   low_G=s_low_G,   low_B=s_low_B,
        meta=s_meta, gray=gray_pos, pattern_oh=s_poh
    )
    return feat, slices

# ------------------------
# ë°ì´í„°ì…‹ êµ¬ì¶• (Y0 ì ˆëŒ€)
# ------------------------
def build_dataset_Y0_abs(ds: VACDataset, knots: np.ndarray,
                         components=('Gamma','Cx','Cy')) -> Tuple[np.ndarray, np.ndarray, FeatureSlices]:
    """
    í–‰ ë‹¨ìœ„: (pk, pattern, gray)
    X: [High Ï†(g) R/G/B | Low Ï†(g) R/G/B | meta | gray_norm | pattern_oh]
    y: ì„ íƒí•œ ì»´í¬ë„ŒíŠ¸(ê°ë§ˆ/Cx/Cy) ìŠ¤ì¹¼ë¼
    - Gammaì˜ gray=0/255 ë° NaNì€ ë“œë¡­
    """
    X_rows, y_vals = [], []
    slices_keep = None

    for s in ds.samples:
        Xd, Yd = s['X'], s['Y']
        for p in PATTERNS:
            for comp in components:
                arr = Yd['Y0'][p][comp]  # (256,)
                for g in range(256):
                    val = arr[g]
                    if comp == 'Gamma' and (g < 1 or g > 254):
                        continue
                    if not np.isfinite(val):   # NaN, inf ì œê±° (Gamma@0/255 ë“±)
                        continue
                    feat, sli = build_feature_vector_for_gray(Xd, p, g, knots, include_controls=True)
                    X_rows.append(feat)
                    y_vals.append(float(val))
                    if slices_keep is None:
                        slices_keep = sli

    X = np.vstack(X_rows).astype(np.float32)
    y = np.asarray(y_vals, dtype=np.float32)
    return X, y, slices_keep

# ------------------------
# í•™ìŠµ / ì €ì¥
# ------------------------
import time

def train_jacobian_models(pk_list: List[int], save_path: str, knots_K=KNOTS):
    start_total = time.time()

    knots = make_knot_positions(K=knots_K)
    ds = VACDataset(pk_list)

    print(f"\n[Jacobian] Start training with {len(pk_list)} PKs, {knots_K} knots")

    artifacts = {"knots": knots.tolist(), "components": {}}

    for comp in COMPONENTS:
        print(f"\n=== Learn Jacobian for Y0-{comp} (vs High) ===")
        t0 = time.time()

        # ë°ì´í„° êµ¬ì¶•
        X, y, feat_slices = build_dataset_Y0_abs(ds, knots, components=(comp,))
        print(f"  â”” X shape: {X.shape}, y shape: {y.shape}")

        # í•™ìŠµ (í‘œì¤€í™” + Ridge)
        model = Pipeline([
            ("scaler", StandardScaler(with_mean=True, with_std=True)),
            ("ridge",  Ridge(alpha=1.0, random_state=RANDOM_STATE))
        ])
        model.fit(X, y)

        # ì‹œê°„ ì¸¡ì •
        t1 = time.time()
        print(f"  â±  Y0-{comp} done in {(t1 - t0):.1f} s")

        ridge = model.named_steps["ridge"]
        scaler = model.named_steps["scaler"]
        coef = ridge.coef_.astype(np.float32)

        artifacts["components"][comp] = {
            "coef": coef.tolist(),
            "intercept": float(ridge.intercept_),
            "feature_slices": {
                "high_R": [feat_slices.high_R.start, feat_slices.high_R.stop],
                "high_G": [feat_slices.high_G.start, feat_slices.high_G.stop],
                "high_B": [feat_slices.high_B.start, feat_slices.high_B.stop],
                "low_R":  [feat_slices.low_R.start,  feat_slices.low_R.stop],
                "low_G":  [feat_slices.low_G.start,  feat_slices.low_G.stop],
                "low_B":  [feat_slices.low_B.start,  feat_slices.low_B.stop],
                "meta":   [feat_slices.meta.start,   feat_slices.meta.stop],
                "gray":   feat_slices.gray,
                "pattern_oh": [feat_slices.pattern_oh.start, feat_slices.pattern_oh.stop],
            },
            "standardizer": {
                "mean": scaler.mean_.astype(np.float32).tolist(),
                "scale": scaler.scale_.astype(np.float32).tolist()
            }
        }

    total_time = time.time() - start_total
    print(f"\nâœ… All components trained in {total_time/60:.1f} min")

    joblib.dump(artifacts, save_path, compress=("gzip", 3))
    print(f"ğŸ“ saved Jacobian model: {save_path}")

# ------------------------
# ìì½”ë¹„ì•ˆ A ìƒì„± í•¨ìˆ˜
# ------------------------
def build_A_for_component(artifacts: dict, comp: str, L=256) -> np.ndarray:
    """
    Î”Y â‰ˆ A Î”h  (ì—¬ê¸°ì„œ Î”hëŠ” [R_high_knots(K), G_high_knots(K), B_high_knots(K)] ìˆœì„œ)
    - í•™ìŠµ ì‹œ 'phi-only' ëª¨ë“œì˜€ìœ¼ë¯€ë¡œ: A[g, k] = Î²_k * Ï†_k(g)
    - R/G/Bë¥¼ ì¢Œìš°ë¡œ ì´ì–´ë¶™ì—¬ Aì˜ ì—´ ìˆ˜ = 3K
    - íŒ¨í„´/ë©”íƒ€ë¥¼ ê³ ì •í•˜ì§€ ì•Šê³  'ê¸°ì € ê¸°ë°˜'ì˜ í‰ê· ì  ìì½”ë¹„ì•ˆ(ëª¨í˜• ê³„ìˆ˜ë§Œ) ë°˜í™˜
      (ìš´ìš© ì‹œ íŒ¨í„´ë³„ Aê°€ í•„ìš”í•˜ë©´, pattern ì›í•«ì„ ê³ ì •í•˜ê³  â€œí•´ë‹¹ íŒ¨í„´ í–‰ë§Œ ì‚¬ìš©â€)
    """
    knots = np.asarray(artifacts["knots"], dtype=np.int32)
    comp_obj = artifacts["components"][comp]
    coef = np.asarray(comp_obj["coef"], dtype=np.float32)
    scale = np.asarray(comp_obj["standardizer"]["scale"], dtype=np.float32)

    s = comp_obj["feature_slices"]
    s_high_R = slice(s["high_R"][0], s["high_R"][1])
    s_high_G = slice(s["high_G"][0], s["high_G"][1])
    s_high_B = slice(s["high_B"][0], s["high_B"][1])

    beta_R = coef[s_high_R] / np.maximum(scale[s_high_R], 1e-12)
    beta_G = coef[s_high_G] / np.maximum(scale[s_high_G], 1e-12)
    beta_B = coef[s_high_B] / np.maximum(scale[s_high_B], 1e-12)

    Phi = stack_basis_all_grays(knots, L=L)  # (L,K)

    # A = [Phi * diag(beta_R) | Phi * diag(beta_G) | Phi * diag(beta_B)]
    A_R = Phi * beta_R.reshape(1, -1)
    A_G = Phi * beta_G.reshape(1, -1)
    A_B = Phi * beta_B.reshape(1, -1)
    A = np.hstack([A_R, A_G, A_B]).astype(np.float32)  # (L, 3K)
    return A
    
def main():
    # 1) PK ëª©ë¡ êµ¬ì„±
    # full_pk_range = list(range(81, 909))
    # exclude = [203, 604, 605, 853, 855, 856]
    # pk_list = [pk for pk in full_pk_range if pk not in exclude]
    pk_list = build_pk_list_for_jacobian()

    # 3) ìì½”ë¹„ì•ˆ í•™ìŠµ ì‹¤í–‰ (ì˜ˆ: Y0=Gamma/Cx/Cy 3ê°œ ëª¨ë‘ Highë§Œì˜ ì˜í–¥)
    #    í•¨ìˆ˜ëª…ì€ ë‹¹ì‹ ì´ ì‚¬ìš© ì¤‘ì¸ ì˜¤í”„ë¼ì¸ í•™ìŠµ í•¨ìˆ˜ë¡œ ë°”ê¾¸ì„¸ìš”.
    train_jacobian_models(pk_list, out_path, knots_K=KNOTS)

if __name__ == "__main__":
    main()
