# train_model.py
import sys
import os
import time
import joblib
import numpy as np
import pandas as pd

from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GroupShuffleSplit, GroupKFold, RandomizedSearchCV
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from scipy.stats import randint, uniform
from joblib import parallel_backend

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from src.modeling.VAC_dataset import VACDataset

RANDOM_STATE = 42

# ê³µí†µ: í•˜ì´ë¸Œë¦¬ë“œ íšŒê·€ (Linear + RF residual) í•™ìŠµ í•¨ìˆ˜
def train_hybrid_regressor(X_all, y_all, groups, tag="", normalize_y=True):
    """
    ì…ë ¥:
      - X_all, y_all: ì „ì²´ ë°ì´í„° (float32 ê¶Œì¥)
      - groups: PK ë‹¨ìœ„ ê·¸ë£¹ ë ˆì´ë¸” (ê¸¸ì´ = X_all í–‰ìˆ˜)
    ìˆ˜í–‰:
      1) Group hold-out (8:2) ë¶„í• 
      2) 1ë‹¨ê³„: StandardScaler â†’ Ridge í•™ìŠµ
      3) 2ë‹¨ê³„: RandomForestRegressorë¡œ residual í•™ìŠµ (RandomizedSearchCV + GroupKFold)
    ë°˜í™˜:
      - artifacts(dict): linear_model, rf_residual, rf_best_params, metrics
    """
    # 1) Group hold-out split
    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)
    train_idx, test_idx = next(gss.split(X_all, y_all, groups))
    X_train, X_test = X_all[train_idx], X_all[test_idx]
    y_train, y_test = y_all[train_idx], y_all[test_idx]
    groups_train = groups[train_idx]
    
    # --- Target standardization (train set stats only)
    if normalize_y:
        y_mean = float(np.nanmean(y_train))
        y_std  = float(np.nanstd(y_train) + 1e-8)  # div-by-zero ë°©ì§€
        y_train_s = (y_train - y_mean) / y_std
    else:
        y_mean, y_std = 0.0, 1.0
        y_train_s = y_train

    # 2) Linear step: Standardize + Ridge
    linear_model = Pipeline([
        ("scaler", StandardScaler(with_mean=True, with_std=True)),
        ("ridge",  Ridge(alpha=1.0, random_state=RANDOM_STATE))
    ])
    t0 = time.time()
    linear_model.fit(X_train, y_train_s)
    t1 = time.time()
    
    # ì˜ˆì¸¡ (í‘œì¤€í™” ìŠ¤í˜ì´ìŠ¤)
    base_pred_train_s = linear_model.predict(X_train)
    base_pred_test_s  = linear_model.predict(X_test)
    
    # ì›-ìŠ¤ì¼€ì¼ë¡œ ë³µì›
    base_pred_test = base_pred_test_s * y_std + y_mean
    base_mse = mean_squared_error(y_test, base_pred_test)
    base_r2  = r2_score(y_test, base_pred_test)
    print(f"â±ï¸ [{tag}] Linear fit: {(t1 - t0):.1f}s | MSE={base_mse:.6f} RÂ²={base_r2:.6f}")

    # 3) RF residual step (í‘œì¤€í™” ìŠ¤í˜ì´ìŠ¤ì—ì„œ residual í•™ìŠµ)
    resid_train_s = (y_train_s - base_pred_train_s).astype(np.float32)
    
    rf = RandomForestRegressor(
        random_state=RANDOM_STATE,
        n_jobs=1,        # ë‚´ë¶€ ë³‘ë ¬ OFF (CVì—ì„œ ë°”ê¹¥ ë³‘ë ¬)
        bootstrap=True
    )
    param_dist = {
        "n_estimators":     randint(120, 300),
        "max_depth":        randint(8, 18),
        "min_samples_split":randint(2, 8),
        "min_samples_leaf": randint(4, 20),
        "max_features":     uniform(0.2, 0.8),
    }
    gkf = GroupKFold(n_splits=3)

    search = RandomizedSearchCV(
        estimator=rf,
        param_distributions=param_dist,
        n_iter=20,
        cv=gkf,
        scoring="r2",
        n_jobs=-1,
        pre_dispatch="2*n_jobs",
        verbose=2,
        random_state=RANDOM_STATE,
        error_score=np.nan,
        return_train_score=True
    )
    t0 = time.time()
    with parallel_backend("threading", n_jobs=-1):
        search.fit(X_train, resid_train_s, groups=groups_train)
    t_resid = time.time() - t0
    
    best_rf = search.best_estimator_
    print(f"â±ï¸ [{tag}] RF(residual) search: {t_resid/60:.1f} min")
    print(f"âœ… [{tag}] RF best params: {search.best_params_}")
    print(f"âœ… [{tag}] RF best RÂ² (CV): {search.best_score_:.6f}")

    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: RF ì˜ˆì¸¡ (í‘œì¤€í™” residual) -> ì›ìŠ¤ì¼€ì¼ ë³µì›
    resid_pred_test_s = best_rf.predict(X_test).astype(np.float32)
    y_pred_hybrid = (base_pred_test_s + resid_pred_test_s) * y_std + y_mean
    final_mse = mean_squared_error(y_test, y_pred_hybrid)
    final_r2  = r2_score(y_test, y_pred_hybrid)
    print(f"ğŸ [{tag}] Hybrid â€” MSE:{final_mse:.6f} RÂ²:{final_r2:.6f}")

    artifacts = {
        "linear_model": linear_model,
        "rf_residual":  best_rf,
        "rf_best_params": search.best_params_,
        "metrics": {
            "linear_only": {"mse": float(base_mse), "r2": float(base_r2)},
            "hybrid":      {"mse": float(final_mse), "r2": float(final_r2)}
        },
        "target_scaler": {"mean": y_mean, "std": y_std, "standardized": bool(normalize_y)},
    }
    return artifacts

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# A) Y0: Gamma / Cx / Cy (per-gray)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        
def train_Y0_models(dataset, save_dir, patterns=('W',), exclude_gray_for_cxcy=(0,5)):
    components = ["dGamma", "dCx", "dCy"]
    channels = ('R_Low','R_High','G_Low','G_High','B_Low','B_High')
    
    for comp in components:
        print(f"\n=== Train Y0: {comp} ===")
        
        # 1) ë°ì´í„° êµ¬ì¶•
        X_all, y_all, groups = dataset.build_XY_dataset(
            target="y0",
            component=comp,
            channels=channels,
            patterns=patterns,
        )

        artifacts = train_hybrid_regressor(X_all, y_all, groups, tag=f"Y0-{comp}")

        payload = {
            "target": {"type": "Y0-per-gray", "component": comp, "patterns": patterns},
            **artifacts,
            "feature_schema": {
                "desc": "Î”LUT(6ch) + meta + gray_norm + LUT_j",
                "channels": list(channels),
                "add_gray_norm": True,
                "add_LUT_j": True,
                "note": f"exclude_gray_for_cxcy={exclude_gray_for_cxcy} is applied inside VACDataset._build_XY0"
            }
        }
        path = os.path.join(save_dir, f"hybrid_{comp}_model.pkl")
        joblib.dump(payload, path, compress=("gzip", 3))
        print(f"ğŸ“ saved: {path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# B) Y1: nor.Lv slope
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_Y1_model(dataset, save_dir, patterns=('W',)):
    print("\n=== Train Y1 ===")
    channels = ('R_Low','R_High','G_Low','G_High','B_Low','B_High')
    
    X_all, y_all, groups = dataset.build_XY_dataset(
    target="y1",
    channels=channels,
    patterns=patterns,
    )

    # y_allì— NaN ìˆëŠ” ê²½ìš° ëŒ€ë¹„
    mask = np.isfinite(y_all)
    X_all = X_all[mask].astype(np.float32)
    y_all = y_all[mask].astype(np.float32)
    groups = groups[mask].astype(np.int64)
    
    artifacts = train_hybrid_regressor(X_all, y_all, groups, tag="Y1-slope")
    
    payload = {
            "target": {"type": "Y1-slope", "patterns": patterns},
            **artifacts,
            "feature_schema": {"desc": "segment-center gray Î”LUT(6ch)+meta+gray_norm+LUT_j"}
    }
    path = os.path.join(save_dir, "hybrid_Y1_slope_model_low_only.pkì•—ì•—l")
    joblib.dump(payload, path, compress=("gzip", 3))
    print(f"ğŸ“ saved: {path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# C) Y2: Î”uâ€²vâ€² (12 Macbeth íŒ¨ì¹˜, íŒ¨ì¹˜ one-hot ì¶”ê°€í•´ í•œ ëª¨ë¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_Y2_model(dataset, save_dir):
    print("\n=== Train Y2 (delta_uv) ===")
    channels = ('R_Low','R_High','G_Low','G_High','B_Low','B_High')

    X_all, y_all, groups = dataset.build_XY_dataset(
        target="y2",
        channels=channels,
    )

    mask = np.isfinite(y_all)
    X_all = X_all[mask].astype(np.float32)
    y_all = y_all[mask].astype(np.float32)
    groups = groups[mask].astype(np.int64)

    artifacts = train_hybrid_regressor(X_all, y_all, groups, tag="Y2-delta_uv")

    payload = {
        "target": {"type": "Y2-delta_uv"},
        **artifacts,
        "feature_schema": {"desc": "3 gray-triplets Î”LUT + meta + pattern one-hot (already inside dataset)"}
    }
    path = os.path.join(save_dir, "hybrid_Y2_delta_uv_model.pkl")
    joblib.dump(payload, path, compress=("gzip", 3))
    print(f"ğŸ“ saved: {path}")
    
    
def preview(name, X, y, groups, n=3):
    print(f"\n[PREVIEW] {name}")
    print("X:", X.shape, "y:", y.shape, "groups:", groups.shape)
    print("finite y ratio:", np.isfinite(y).mean())
    print("y min/max:", np.nanmin(y), np.nanmax(y))
    print("unique groups:", len(np.unique(groups)))
    print("first rows X[0:3]:\n", X[:n, :3])
    print("first y:", y[:n], "first groups:", groups[:n])
    
def main():
    BYPASS_PK = 3007
    # # -------------------------------------------
    # # 1) í•™ìŠµì— ì‚¬ìš©í•  PK ë¦¬ìŠ¤íŠ¸ì™€ bypass PK ì„¤ì •    
    # # -------------------------------------------
    # full_pk_range = list(range(1411, 2455))
    # exclude_pks = [1934, 2154] # í•™ìŠµ ì œì™¸ PKs
    # pk_list = [pk for pk in full_pk_range if pk not in exclude_pks]
    # print(f"â–¶ TEST with {len(pk_list)} PKs")

    # # -------------------------------------------
    # # 2) ë°ì´í„°ì…‹ ìƒì„±
    # # -------------------------------------------
    # dataset = VACDataset(pk_list)
    
    # # -------------------------------------------
    # # 3) ì €ì¥ ê²½ë¡œ
    # # -------------------------------------------
    # save_dir = os.path.dirname(__file__)
    
    # # -------------------------------------------
    # # 4) í•™ìŠµ ì‹¤í–‰ (Y0 â†’ Y1 â†’ Y2)
    # # -------------------------------------------
    # train_Y0_models(dataset, save_dir, patterns=('W',))
    # # train_Y1_model(dataset, save_dir, patterns=('W',), use_full_range=True)
    # # train_Y2_model(dataset, save_dir)

    # print("\nâœ… ALL DONE.")
    
    # ================== Dataset ê²€ì¦ìš© ì¶œë ¥ ==================
    print("TEST")
    pd.set_option('display.max_columns', None)
    test_pk = [3008]
    dataset = VACDataset(test_pk, ref_pk=BYPASS_PK)

    X, y, groups = dataset.build_XY_dataset(
        target="y0",
        component="dGamma",
        channels=('R_Low','R_High','G_Low','G_High','B_Low','B_High'),
        patterns=('W','R','G','B'),
    )

    print(f"\n[PK=3007 Y0 Dataset Preview]")
    print(f"X_mat shape: {X.shape}")   # (255, Dx)
    print(f"y_vec shape: {y.shape}")   # (255,)
    print("\n--- X_mat (first 3 rows) ---")
    print(pd.DataFrame(X[:3]))         # ì•ë¶€ë¶„ ì¼ë¶€ í™•ì¸
    print("\n--- y_vec (first 10 values) ---")
    print(y[:10])

ë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ ì•„ë˜ì²˜ëŸ¼ ë‚˜ì˜µë‹ˆë‹¤. 

[PK=3007 Y0 Dataset Preview]
X_mat shape: (253, 15)
y_vec shape: (253,)

--- X_mat (first 3 rows) ---
     0     1     2     3     4     5    6    7    8    9    10    11    12  \
0 -14.0   7.0 -14.0   7.0 -14.0   7.0  0.0  0.0  0.0  0.0  1.0  60.0  26.0
1 -31.0  15.0 -31.0  15.0 -31.0  15.0  0.0  0.0  0.0  0.0  1.0  60.0  26.0
2 -45.0  22.0 -45.0  22.0 -45.0  22.0  0.0  0.0  0.0  0.0  1.0  60.0  26.0

         13    14
0  0.007843  16.0
1  0.011765  36.0
2  0.015686  52.0

--- y_vec (first 10 values) ---
[ 1.3256073e-04  1.5616560e-01 -9.7430944e-02  1.6355515e-04
  1.7142296e-04 -1.9010544e-02 -1.9743919e-02 -2.8309345e-02
 -2.1104097e-02 -1.6113281e-02]


6    7    8    9    10 = panal_maker (one-hot)
11 = frame_rate
12 = model_year
13 = nor_gray
14 = lut_index

ì´ë ‡ê²Œ ë©ë‹ˆë‹¤. ë³´ì‹œë‹¤ì‹œí”¼ íŒ¨í„´ì€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í¬í•¨í•˜ëŠ”ê²Œ ì¢‹ì„ê¹Œìš”? W íŒ¨í„´ë§Œ ì‚¬ìš©í•˜ê¸´ í•©ë‹ˆë‹¤ë§Œ,,, 

íŒ¨í„´ ì •ë³´ë¥¼ Xì— í¬í•¨ì‹œí‚¬ ê²½ìš° ì–´ë””ë¥¼ ìˆ˜ì •í•˜ë©´ ë˜ëŠ”ì§€ì™€,

ìœ„ ì½”ë“œ ê¸°ì¤€ í•™ìŠµ ì‹¤í–‰ì€ ì–´ë–»ê²Œ í•˜ë©´ ë˜ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.
(ref_pk=BAPASS_PK, target_pk_list=3008~3316
